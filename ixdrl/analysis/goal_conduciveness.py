import logging
import numpy as np
from typing import Optional
from ixdrl import Rollouts
from ixdrl.analysis import RolloutsAnalyses
from ixdrl.analysis.value import ValueAnalysis
from ixdrl.util.math import normalized_derivative

__author__ = 'Pedro Sequeira'
__email__ = 'pedro.sequeira@sri.com'

SCALE_FACTOR = 100  # factor used to scale values before computing derivative


class GoalConducivenessAnalysis(ValueAnalysis):
    """
    This analysis captures how desirable a situation is with respect to the agentâ€™s goals, having into account the
    context of the decision point, i.e., the previous timesteps.
    We compute goal conduciveness by using the first derivative of the value function with respect to time, and then
    use the sine function over the angle generated by the derivative (in an imaginary unit circle centered at the
    decision point's value) to normalize confidence. The output values are in the range [-1,1].
    """

    def __init__(self, derivative_accuracy: int = 4, num_processes: int = 1):
        """
        Creates a new goal conduciveness analysis.
        :param int derivative_accuracy: the accuracy used to compute the value function derivative using finite 
        difference method. Needs to be a positive, even number.
        :param int num_processes: the number of parallel processes to use for this analysis. A value of `-1` or `None`
        will use all available cpus.
        """
        assert derivative_accuracy > 0 and derivative_accuracy % 2 == 0, \
            f'Accuracy has to be a positive, even number, but {derivative_accuracy} was provided.'
        super().__init__(num_processes)
        self.name = 'Goal Conduciveness'
        self.derivative_accuracy = derivative_accuracy

    def analyze(self, rollouts: Rollouts) -> Optional[RolloutsAnalyses]:

        # perform analysis over all rollouts
        all_analyses = self._analyze_parallel(self._get_value, rollouts)  # get value first
        if all_analyses is None:
            logging.error('Cannot compute goal conduciveness: no valid value data available in the datapoints.')
            return None  # cannot extract confidence from data

        # normalize value and clip values across data
        for dim, analyses in all_analyses.items():
            values = np.concatenate([value.flatten() for value in analyses.values()])
            _minV = np.min(values)
            _maxV = np.max(values)
            for rollout_id, values in analyses.items():
                values = (values - _minV) / (_maxV - _minV)  # normalize values in [0,1]
                values *= SCALE_FACTOR  # increase magnitude to get more prominent derivative

                # check sufficient data to perform derivatives
                original_len = len(values)
                min_len = self.derivative_accuracy + 2
                if original_len < min_len:
                    start_idx = int(min_len / 2 - original_len / 2)
                    new_values = np.full(min_len, values[-1])
                    new_values[:start_idx] = values[0]
                    new_values[start_idx:start_idx + original_len] = values
                    values = new_values  # stretch array

                # compute goal conduciveness G(t)=sine(arctan(d/dt V(s_t )) ) from discrete first derivative
                # ensure that only value of past timesteps is used to approximate derivative
                goal_cond = normalized_derivative(values, order=1, accuracy=self.derivative_accuracy,
                                                  fd_type='backward')

                if min_len > original_len:
                    # select correct indices such that it matches original length
                    start_idx = int(min_len / 2 - original_len / 2)
                    goal_cond = goal_cond[start_idx:start_idx + original_len]

                analyses[rollout_id] = goal_cond

        return all_analyses
